{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"darcyai Generating documentation Follow these steps to get some automatically generated code documentation $ pip install pydoc-markdown>=4.0.0,<5.0.0 mkdocs $ ./apidocs.bash # (to run live docs on localhost:8000) $ ./apidocs.bash --generate # (to output the docs to docs directory)","title":"Home"},{"location":"#darcyai","text":"","title":"darcyai"},{"location":"#generating-documentation","text":"Follow these steps to get some automatically generated code documentation $ pip install pydoc-markdown>=4.0.0,<5.0.0 mkdocs $ ./apidocs.bash # (to run live docs on localhost:8000) $ ./apidocs.bash --generate # (to output the docs to docs directory)","title":"Generating documentation"},{"location":"config/","text":"darcyai.config [view_source] Config Objects class Config() [view_source] Class to hold the configuration for the Perceptor. Arguments name ( str ): The name of the config. config_type ( str ): The type of the config. Valid types are: int float bool str default_value ( Any ): The default value of the config. description ( str ): The description of the config. is_valid def is_valid(value: Any) -> bool [view_source] Checks if the value is valid for the config. Arguments value ( Any ): The value to check. Returns bool : True if the value is valid, False otherwise. cast def cast(value: Any) -> Any [view_source] Casts the value to the type of the config. Arguments value ( Any ): The value to cast. Returns Any : The casted value.","title":"Config"},{"location":"config/#darcyaiconfig","text":"[view_source]","title":"darcyai.config"},{"location":"config/#config-objects","text":"class Config() [view_source] Class to hold the configuration for the Perceptor. Arguments name ( str ): The name of the config. config_type ( str ): The type of the config. Valid types are: int float bool str default_value ( Any ): The default value of the config. description ( str ): The description of the config.","title":"Config Objects"},{"location":"config/#is_valid","text":"def is_valid(value: Any) -> bool [view_source] Checks if the value is valid for the config. Arguments value ( Any ): The value to check. Returns bool : True if the value is valid, False otherwise.","title":"is_valid"},{"location":"config/#cast","text":"def cast(value: Any) -> Any [view_source] Casts the value to the type of the config. Arguments value ( Any ): The value to cast. Returns Any : The casted value.","title":"cast"},{"location":"perceptionobjectmodel/","text":"darcyai.perception_object_model [view_source] PerceptionObjectModel Objects class PerceptionObjectModel(Serializable) [view_source] This class is used to represent the perception of an object. set_value def set_value(key: str, value: Any) -> None [view_source] Set the value of a key in the perception object model. Arguments key ( str ): The key to set. value ( Any ): The value to set. get_perceptor def get_perceptor(name: str) -> Any [view_source] Get the perception result of the provided perceptor. Arguments name ( str ): The name of the perceptor. Returns Any : The result of the perception. get_perceptors def get_perceptors() -> List[str] [view_source] Returns list of the perceptors. Returns List[str] : The list of the perceptors. serialize def serialize() -> Dict[str, Any] [view_source] Serialize the perception object model. Returns Dict[str, Any] - The serialized perception object model. set_input_data def set_input_data(input_data: StreamData) -> None [view_source] Set the input data for the perception object model. Arguments input_data ( StreamData ): The input data. get_input_data def get_input_data() -> StreamData [view_source] Get the input data for the perception object model. Returns StreamData : The input data. set_pulse_number def set_pulse_number(pulse_number: int) -> None [view_source] Set the pulse number for the perception object model. Arguments pulse_number ( int ): The pulse number. get_pulse_number def get_pulse_number() -> int [view_source] Get the pulse number for the perception object model. Returns int : The pulse number.","title":"PerceptionObjectModel"},{"location":"perceptionobjectmodel/#darcyaiperception_object_model","text":"[view_source]","title":"darcyai.perception_object_model"},{"location":"perceptionobjectmodel/#perceptionobjectmodel-objects","text":"class PerceptionObjectModel(Serializable) [view_source] This class is used to represent the perception of an object.","title":"PerceptionObjectModel Objects"},{"location":"perceptionobjectmodel/#set_value","text":"def set_value(key: str, value: Any) -> None [view_source] Set the value of a key in the perception object model. Arguments key ( str ): The key to set. value ( Any ): The value to set.","title":"set_value"},{"location":"perceptionobjectmodel/#get_perceptor","text":"def get_perceptor(name: str) -> Any [view_source] Get the perception result of the provided perceptor. Arguments name ( str ): The name of the perceptor. Returns Any : The result of the perception.","title":"get_perceptor"},{"location":"perceptionobjectmodel/#get_perceptors","text":"def get_perceptors() -> List[str] [view_source] Returns list of the perceptors. Returns List[str] : The list of the perceptors.","title":"get_perceptors"},{"location":"perceptionobjectmodel/#serialize","text":"def serialize() -> Dict[str, Any] [view_source] Serialize the perception object model. Returns Dict[str, Any] - The serialized perception object model.","title":"serialize"},{"location":"perceptionobjectmodel/#set_input_data","text":"def set_input_data(input_data: StreamData) -> None [view_source] Set the input data for the perception object model. Arguments input_data ( StreamData ): The input data.","title":"set_input_data"},{"location":"perceptionobjectmodel/#get_input_data","text":"def get_input_data() -> StreamData [view_source] Get the input data for the perception object model. Returns StreamData : The input data.","title":"get_input_data"},{"location":"perceptionobjectmodel/#set_pulse_number","text":"def set_pulse_number(pulse_number: int) -> None [view_source] Set the pulse number for the perception object model. Arguments pulse_number ( int ): The pulse number.","title":"set_pulse_number"},{"location":"perceptionobjectmodel/#get_pulse_number","text":"def get_pulse_number() -> int [view_source] Get the pulse number for the perception object model. Returns int : The pulse number.","title":"get_pulse_number"},{"location":"perceptor/","text":"darcyai.perceptor.perceptor [view_source] Perceptor Objects class Perceptor(Configurable, EventEmitter) [view_source] The Perceptor class is the base class for all perceptors. Arguments model_path ( str ): The path to the model file. Examples >>> from darcyai.perceptor import Perceptor >>> class MyPerceptor(Perceptor): >>> def __init__(self): ... Perceptor.__init__(self, \"path/to/model\") >>> def run(self, input_data): ... return input_data.data >>> def load(self): ... pass run def run(input_data: Any, config: ConfigRegistry = None) -> Any [view_source] Runs the perceptor on the input data. Arguments input_data ( StreamData ): The input data to run the perceptor on. config ( ConfigRegistry ): The configuration for the perceptor. Defaults to None . Returns Any : The output of the perceptor. load def load(accelerator_idx: Union[int, None] = None) -> None [view_source] Loads the perceptor. Arguments accelerator_idx ( int, None ): The index of the accelerator to load the perceptor on. Defaults to None . is_loaded def is_loaded() -> bool [view_source] Checks if the perceptor is loaded. Returns bool : True if the perceptor is loaded, False otherwise. set_loaded def set_loaded(loaded: bool) -> None [view_source] Sets the perceptor loaded state. Arguments loaded ( bool ): The loaded state. set_config_value def set_config_value(key: str, value: Any) [view_source] Sets a config value. Arguments key ( str ): The key of the config. value ( Any ): The value to set. get_config_value def get_config_value(key: str) -> Any [view_source] Gets a config value. Arguments key ( str ): The key of the config. Returns Any : The value of the config. init_config_registry def init_config_registry() [view_source] Initializes the config registry.","title":"Perceptor"},{"location":"perceptor/#darcyaiperceptorperceptor","text":"[view_source]","title":"darcyai.perceptor.perceptor"},{"location":"perceptor/#perceptor-objects","text":"class Perceptor(Configurable, EventEmitter) [view_source] The Perceptor class is the base class for all perceptors. Arguments model_path ( str ): The path to the model file. Examples >>> from darcyai.perceptor import Perceptor >>> class MyPerceptor(Perceptor): >>> def __init__(self): ... Perceptor.__init__(self, \"path/to/model\") >>> def run(self, input_data): ... return input_data.data >>> def load(self): ... pass","title":"Perceptor Objects"},{"location":"perceptor/#run","text":"def run(input_data: Any, config: ConfigRegistry = None) -> Any [view_source] Runs the perceptor on the input data. Arguments input_data ( StreamData ): The input data to run the perceptor on. config ( ConfigRegistry ): The configuration for the perceptor. Defaults to None . Returns Any : The output of the perceptor.","title":"run"},{"location":"perceptor/#load","text":"def load(accelerator_idx: Union[int, None] = None) -> None [view_source] Loads the perceptor. Arguments accelerator_idx ( int, None ): The index of the accelerator to load the perceptor on. Defaults to None .","title":"load"},{"location":"perceptor/#is_loaded","text":"def is_loaded() -> bool [view_source] Checks if the perceptor is loaded. Returns bool : True if the perceptor is loaded, False otherwise.","title":"is_loaded"},{"location":"perceptor/#set_loaded","text":"def set_loaded(loaded: bool) -> None [view_source] Sets the perceptor loaded state. Arguments loaded ( bool ): The loaded state.","title":"set_loaded"},{"location":"perceptor/#set_config_value","text":"def set_config_value(key: str, value: Any) [view_source] Sets a config value. Arguments key ( str ): The key of the config. value ( Any ): The value to set.","title":"set_config_value"},{"location":"perceptor/#get_config_value","text":"def get_config_value(key: str) -> Any [view_source] Gets a config value. Arguments key ( str ): The key of the config. Returns Any : The value of the config.","title":"get_config_value"},{"location":"perceptor/#init_config_registry","text":"def init_config_registry() [view_source] Initializes the config registry.","title":"init_config_registry"},{"location":"pipeline/","text":"darcyai.pipeline [view_source] Pipeline Objects class Pipeline() [view_source] The Pipeline class is the main class of the darcyai package. Arguments input_stream ( InputStream ): The input stream to be used by the pipeline. input_data_history_len ( int ): The number of input data items to be stored in the history. Defaults to 1 . pom_history_len ( int ): The number of POM items to be stored in the history. Defaults to 1 . metrics_history_len ( int ): The number of metrics items to be stored in the history. Defaults to 1 . num_of_edge_tpus ( int ): The number of Edge TPUs. Defaults to 1 . perceptor_error_handler_callback ( Callable[[str, Exception], None] ): The callback function to be called when a Perceptor throws an exception. Defaults to None . output_stream_error_handler_callback ( Callable[[str, Exception], None] ): The callback function to be called when an OutputStream throws an exception. Defaults to None . input_stream_error_handler_callback ( Callable[[Exception], None] ): The callback function to be called when an InputStream throws an exception. Defaults to None . perception_completion_callback ( Callable[[PerceptionObjectModel], None] ): The callback function to be called when all the perceptors have completed processing. Defaults to None . universal_rest_api ( bool ): Whether or not to use the universal REST API. Defaults to False . rest_api_base_path ( str ): The base path of the REST API. Defaults to / . rest_api_flask_app ( Flask ): The Flask application to be used by the REST API. Defaults to None . rest_api_port ( int ): The port of the REST API. Defaults to 5000 . rest_api_host ( str ): The host of the REST API. Defaults to localhost . Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera, ... input_data_history_len=10, ... pom_history_len=10, ... metrics_history_len=10, ... num_of_edge_tpus=1, ... perceptor_error_handler_callback=None, ... output_stream_error_handler_callback=None, ... input_stream_error_handler_callback=None, ... perception_completion_callback=None, ... pulse_completion_callback=None, ... universal_rest_api=True, ... rest_api_base_path=\"/\", ... rest_api_flask_app=None, ... rest_api_port=5000, ... rest_api_host=\"localhost\") num_of_edge_tpus def num_of_edge_tpus() -> int [view_source] Gets the number of Edge TPUs in the pipeline. Returns int : The number of Edge TPUs in the pipeline. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.num_of_edge_tpus() add_perceptor def add_perceptor(name: str, perceptor: Perceptor, input_callback: Callable[[StreamData, PerceptionObjectModel, ConfigRegistry], Any] = None, output_callback: Callable[[Any, PerceptionObjectModel, ConfigRegistry], Any] = None, parent: str = None, multi: bool = False, accelerator_idx: Union[int, None] = None, default_config: Dict[str, Any] = None) -> None [view_source] Adds a new Perceptor to the pipeline. Arguments name ( str ): The name of the Perceptor (must be a valid variable name). perceptor ( Perceptor ): The Perceptor to be added. input_callback ( Callable[[StreamData, PerceptionObjectModel, ConfigRegistry], Any] ): The callback function to be called when the Perceptor receives input data. Defaults to None . output_callback ( Callable[[Any, PerceptionObjectModel, ConfigRegistry], Any] ): The callback function to be called when the Perceptor produces output data. Defaults to None . parent ( str ): The name of the parent Perceptor. Defaults to None . multi ( bool ): Whether or not to run the perceptor for each item in input data. Defaults to False . accelerator_idx ( int ): The index of the Edge TPU to be used by the Perceptor. Defaults to None . default_config ( Dict[str, Any] ): The default configuration for the Perceptor. Defaults to None . Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.add_perceptor(name=\"perceptor\", ... perceptor=MyPerceptor(), ... input_callback=None, ... output_callback=None, ... parent=\"input_stream\", ... multi=True, ... accelerator_idx=0, ... default_config={\"key\": \"value\"}) add_perceptor_before def add_perceptor_before(name_to_insert_before: str, name: str, perceptor: Perceptor, input_callback: Callable[[StreamData, PerceptionObjectModel, ConfigRegistry], Any] = None, output_callback: Callable[[Any, PerceptionObjectModel, ConfigRegistry], Any] = None, multi: bool = False, accelerator_idx: Union[int, None] = None, default_config: dict = None) -> None [view_source] Adds a new Perceptor to the pipeline. Arguments name_to_insert_before ( str ): The name of the Perceptor to insert the new Perceptor before. name ( str ): The name of the Perceptor. perceptor ( Perceptor ): The Perceptor to be added. input_callback ( Callable[[StreamData, PerceptionObjectModel, ConfigRegistry], Any] ): The callback function to be called when the Perceptor receives input data. Defaults to None . output_callback ( Callable[[Any, PerceptionObjectModel, ConfigRegistry], Any] ): The callback function to be called when the Perceptor produces output data. Defaults to None . multi ( bool ): Whether or not to run the perceptor for each item in input data. Defaults to False . accelerator_idx ( int ): The index of the Edge TPU to be used by the Perceptor. Defaults to None . default_config ( dict ): The default configuration for the Perceptor. Defaults to None . Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.add_perceptor_before(name=\"perceptor\", ... name_to_insert_before=\"child_input_stream\", ... perceptor=MyPerceptor(), ... input_callback=None, ... output_callback=None, ... multi=True, ... accelerator_idx=0, ... default_config={\"key\": \"value\"}) add_perceptor_after def add_perceptor_after(name_to_insert_after: str, name: str, perceptor: Perceptor, input_callback: Callable[[StreamData, PerceptionObjectModel, ConfigRegistry], Any] = None, output_callback: Callable[[Any, PerceptionObjectModel, ConfigRegistry], Any] = None, multi: bool = False, accelerator_idx: Union[int, None] = None, default_config: dict = None) -> None [view_source] Adds a new Perceptor to the pipeline. Arguments name_to_insert_after ( str ): The name of the Perceptor to insert the new Perceptor after. name ( str ): The name of the Perceptor. perceptor ( Perceptor ): The Perceptor to be added. input_callback ( Callable[[StreamData, PerceptionObjectModel, Any], ConfigRegistry] ): The callback function to be called when the Perceptor receives input data. Defaults to None . output_callback ( Callable[[Any, PerceptionObjectModel, ConfigRegistry], Any] ): The callback function to be called when the Perceptor produces output data. Defaults to None . multi ( bool ): Whether or not to run the perceptor for each item in input data. Defaults to False . accelerator_idx ( int ): The index of the Edge TPU to be used by the Perceptor. Defaults to None . default_config ( dict ): The default configuration for the Perceptor. Defaults to None . Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.add_perceptor_after(name=\"perceptor\", ... name_to_insert_after=\"parent_input_stream\", ... perceptor=MyPerceptor(), ... input_callback=None, ... output_callback=None, ... multi=True, ... accelerator_idx=0, ... default_config={\"key\": \"value\"}) add_parallel_perceptor def add_parallel_perceptor(name_to_insert_in_parallel_with: str, name: str, perceptor: Perceptor, input_callback: Callable[[StreamData, PerceptionObjectModel, ConfigRegistry], Any] = None, output_callback: Callable[[Any, PerceptionObjectModel, ConfigRegistry], Any] = None, multi: bool = False, accelerator_idx: Union[int, None] = None, default_config: dict = None) -> None [view_source] Adds a new Perceptor to the pipeline. Arguments name_to_insert_in_parallel_with ( str ): The name of the Perceptor to insert the new Perceptor in parallel with. name ( str ): The name of the Perceptor. perceptor ( Perceptor ): The Perceptor to be added. input_callback ( Callable[[StreamData, PerceptionObjectModel, ConfigRegistry], Any] ): The callback function to be called when the Perceptor receives input data. Defaults to None . output_callback ( Callable[[Any, PerceptionObjectModel, ConfigRegistry], Any] ): The callback function to be called when the Perceptor produces output data. Defaults to None . multi ( bool ): Whether or not to run the perceptor for each item in input data. Defaults to False . accelerator_idx ( int ): The index of the Edge TPU to be used by the Perceptor. Defaults to None . default_config ( dict ): The default configuration for the Perceptor. Defaults to None . Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.add_parallel_perceptor(name=\"perceptor\", ... name_to_insert_in_parallel_with=\"parallel_input_stream\", ... perceptor=MyPerceptor(), ... input_callback=None, ... output_callback=None, ... multi=True, ... accelerator_idx=0, ... default_config={\"key\": \"value\"}) update_input_stream def update_input_stream(input_stream: InputStream) -> None [view_source] Updates the input stream of the pipeline. Arguments input_stream ( InputStream ): The input stream to be added. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.update_input_stream(camera) <a id=\"darcyai.pipeline.Pipeline.add_output_stream\"></a> #### add\\_output\\_stream ```python def add_output_stream(name: str, callback: Callable[[PerceptionObjectModel, StreamData], Any], output_stream: OutputStream, default_config: dict = None) -> None [view_source] Adds an OutputStream to the pipeline. Arguments name ( str ): The name of the OutputStream. callback ( Callable[[PerceptionObjectModel, StreamData], Any] ): A callback function that is called whith PerceptionObjectModel object and returns the data that the output stream must process. output_stream ( OutputStream ): The OutputStream to be added. default_config ( dict ): The default configuration for the OutputStream. Defaults to None . Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.add_output_stream(name=\"output_stream\", ... callback=None, ... output_stream=MyOutputStream(), ... default_config={\"key\": \"value\"}) remove_output_stream def remove_output_stream(name: str) -> None [view_source] Removes an OutputStream from the pipeline. Arguments name ( str ): The name of the OutputStream to be removed. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera)\\ >>> pipeline.add_output_stream(name=\"output_stream\", ... callback=None, ... output_stream=MyOutputStream(), ... default_config={\"key\": \"value\"}) >>> pipeline.remove_output_stream(name=\"output_stream\") stop def stop() -> None [view_source] Stops the pipeline. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.stop() run def run() -> None [view_source] Runs the pipeline. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.run() get_pom def get_pom() -> PerceptionObjectModel [view_source] Gets the Perception Object Model. Returns PerceptionObjectModel : The Perception Object Model. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pom = pipeline.get_pom() get_current_pulse_number def get_current_pulse_number() -> int [view_source] Gets the current pulse number. Returns int : The current pulse number. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pulse_number = pipeline.get_current_pulse_number() get_latest_input def get_latest_input() -> StreamData [view_source] Gets the latest input data. Returns StreamData : The latest input data. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> latest_input = pipeline.get_latest_input() get_historical_input def get_historical_input(pulse_number: int) -> StreamData [view_source] Gets the input data from the history. Arguments pulse_number ( int ): The pulse number. Returns StreamData : The input data from the history. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> historical_input = pipeline.get_historical_input(pulse_number=1) get_input_history def get_input_history() -> Dict[int, StreamData] [view_source] Gets the input data history. Returns Dict[int, StreamData] - The input data history. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> input_history = pipeline.get_input_history() get_historical_pom def get_historical_pom(pulse_number: int) -> PerceptionObjectModel [view_source] Gets the POM from the history. Arguments pulse_number ( int ): The pulse number. Returns PerceptionObjectModel : The POM from the history. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> historical_pom = pipeline.get_historical_pom(pulse_number=1) get_pom_history def get_pom_history() -> Dict[int, PerceptionObjectModel] [view_source] Gets the POM history. Returns Dict[int, PerceptionObjectModel] - The POM history. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pom_history = pipeline.get_pom_history() run_perceptor def run_perceptor(perceptor: Perceptor, input_data: Any, multi: bool = False) -> Any [view_source] Runs the Perceptor. Arguments perceptor ( Perceptor ): The Perceptor to be run. input_data ( Any ): The input data. multi ( bool ): Whether or not to run the perceptor for each item in input data. Defaults to False . Returns Any : The result of running the Perceptor. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> result = pipeline.run_perceptor(perceptor=Perceptor(), input_data=None, multi=True) get_graph def get_graph() -> Any [view_source] Gets the graph of the perceptors. Returns Any : The graph of the perceptors. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> graph = pipeline.get_graph() get_all_performance_metrics def get_all_performance_metrics() -> Dict[str, Any] [view_source] Gets the performance metrics of the pipeline. Returns Dict[str, Any] - The performance metrics of the pipeline. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> metrics = pipeline.get_all_performance_metrics() get_pulse_performance_metrics def get_pulse_performance_metrics(pulse_number: Union[int, None] = None) -> Dict[str, Any] [view_source] Gets the performance metrics of the pipeline for specific pulse. Arguments pulse_number ( int ): The pulse number of the pulse. Defaults to current pulse. Defaults to None . Returns Dict[str, Any] - The performance metrics of the pipeline for specific pulse. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> metrics = pipeline.get_pulse_performance_metrics(pulse_number=1) get_perceptor_performance_metrics def get_perceptor_performance_metrics(name: str, pulse_number: Union[int, None] = None) -> Dict[str, Any] [view_source] Gets the performance metrics of the pipeline for specific perceptor. Arguments name ( str ): The name of the perceptor. pulse_number ( int ): The pulse number of the pulse. Defaults to current pulse. Defaults to None . Returns Dict[str, Any] - The performance metrics of the pipeline for specific perceptor. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> metrics = pipeline.get_perceptor_performance_metrics(name=\"perceptor_name\", ... pulse_number=1) set_perceptor_config def set_perceptor_config(perceptor_name: str, name: str, value: Any) -> None [view_source] Sets the config of the pipeline. Arguments perceptor_name ( str ): The name of the perceptor. name ( str ): The name of the config. value ( Any ): The value of the config. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.set_perceptor_config(perceptor_name=\"perceptor_name\", ... name=\"config_name\", ... value=1) get_perceptor_config def get_perceptor_config(perceptor_name: str) -> Dict[str, Tuple[Any, Config]] [view_source] Gets the config of the perceptor. Arguments perceptor_name ( str ): The name of the perceptor. Returns Dict[str, Tuple[Any, Config]] - The config of the perceptor. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> config = pipeline.get_perceptor_config(perceptor_name=\"perceptor_name\") set_output_stream_config def set_output_stream_config(name: str, config_name: str, value: Any) -> None [view_source] Sets the config of the output stream. Arguments name ( str ): The name of the output stream. config_name ( str ): The name of the config. value ( Any ): The value of the config. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.set_output_stream_config(name=\"output_stream_name\", ... config_name=\"config_name\", ... value=1) get_output_stream_config def get_output_stream_config(name: str) -> Dict[str, Tuple[Any, Config]] [view_source] Gets the config of the output stream. Arguments name ( str ): The name of the output stream. Returns Dict[str, Tuple[Any, Config]] - The config of the output stream. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> config = pipeline.get_output_stream_config(name=\"output_stream_name\")","title":"Pipeline"},{"location":"pipeline/#darcyaipipeline","text":"[view_source]","title":"darcyai.pipeline"},{"location":"pipeline/#pipeline-objects","text":"class Pipeline() [view_source] The Pipeline class is the main class of the darcyai package. Arguments input_stream ( InputStream ): The input stream to be used by the pipeline. input_data_history_len ( int ): The number of input data items to be stored in the history. Defaults to 1 . pom_history_len ( int ): The number of POM items to be stored in the history. Defaults to 1 . metrics_history_len ( int ): The number of metrics items to be stored in the history. Defaults to 1 . num_of_edge_tpus ( int ): The number of Edge TPUs. Defaults to 1 . perceptor_error_handler_callback ( Callable[[str, Exception], None] ): The callback function to be called when a Perceptor throws an exception. Defaults to None . output_stream_error_handler_callback ( Callable[[str, Exception], None] ): The callback function to be called when an OutputStream throws an exception. Defaults to None . input_stream_error_handler_callback ( Callable[[Exception], None] ): The callback function to be called when an InputStream throws an exception. Defaults to None . perception_completion_callback ( Callable[[PerceptionObjectModel], None] ): The callback function to be called when all the perceptors have completed processing. Defaults to None . universal_rest_api ( bool ): Whether or not to use the universal REST API. Defaults to False . rest_api_base_path ( str ): The base path of the REST API. Defaults to / . rest_api_flask_app ( Flask ): The Flask application to be used by the REST API. Defaults to None . rest_api_port ( int ): The port of the REST API. Defaults to 5000 . rest_api_host ( str ): The host of the REST API. Defaults to localhost . Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera, ... input_data_history_len=10, ... pom_history_len=10, ... metrics_history_len=10, ... num_of_edge_tpus=1, ... perceptor_error_handler_callback=None, ... output_stream_error_handler_callback=None, ... input_stream_error_handler_callback=None, ... perception_completion_callback=None, ... pulse_completion_callback=None, ... universal_rest_api=True, ... rest_api_base_path=\"/\", ... rest_api_flask_app=None, ... rest_api_port=5000, ... rest_api_host=\"localhost\")","title":"Pipeline Objects"},{"location":"pipeline/#num_of_edge_tpus","text":"def num_of_edge_tpus() -> int [view_source] Gets the number of Edge TPUs in the pipeline. Returns int : The number of Edge TPUs in the pipeline. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.num_of_edge_tpus()","title":"num_of_edge_tpus"},{"location":"pipeline/#add_perceptor","text":"def add_perceptor(name: str, perceptor: Perceptor, input_callback: Callable[[StreamData, PerceptionObjectModel, ConfigRegistry], Any] = None, output_callback: Callable[[Any, PerceptionObjectModel, ConfigRegistry], Any] = None, parent: str = None, multi: bool = False, accelerator_idx: Union[int, None] = None, default_config: Dict[str, Any] = None) -> None [view_source] Adds a new Perceptor to the pipeline. Arguments name ( str ): The name of the Perceptor (must be a valid variable name). perceptor ( Perceptor ): The Perceptor to be added. input_callback ( Callable[[StreamData, PerceptionObjectModel, ConfigRegistry], Any] ): The callback function to be called when the Perceptor receives input data. Defaults to None . output_callback ( Callable[[Any, PerceptionObjectModel, ConfigRegistry], Any] ): The callback function to be called when the Perceptor produces output data. Defaults to None . parent ( str ): The name of the parent Perceptor. Defaults to None . multi ( bool ): Whether or not to run the perceptor for each item in input data. Defaults to False . accelerator_idx ( int ): The index of the Edge TPU to be used by the Perceptor. Defaults to None . default_config ( Dict[str, Any] ): The default configuration for the Perceptor. Defaults to None . Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.add_perceptor(name=\"perceptor\", ... perceptor=MyPerceptor(), ... input_callback=None, ... output_callback=None, ... parent=\"input_stream\", ... multi=True, ... accelerator_idx=0, ... default_config={\"key\": \"value\"})","title":"add_perceptor"},{"location":"pipeline/#add_perceptor_before","text":"def add_perceptor_before(name_to_insert_before: str, name: str, perceptor: Perceptor, input_callback: Callable[[StreamData, PerceptionObjectModel, ConfigRegistry], Any] = None, output_callback: Callable[[Any, PerceptionObjectModel, ConfigRegistry], Any] = None, multi: bool = False, accelerator_idx: Union[int, None] = None, default_config: dict = None) -> None [view_source] Adds a new Perceptor to the pipeline. Arguments name_to_insert_before ( str ): The name of the Perceptor to insert the new Perceptor before. name ( str ): The name of the Perceptor. perceptor ( Perceptor ): The Perceptor to be added. input_callback ( Callable[[StreamData, PerceptionObjectModel, ConfigRegistry], Any] ): The callback function to be called when the Perceptor receives input data. Defaults to None . output_callback ( Callable[[Any, PerceptionObjectModel, ConfigRegistry], Any] ): The callback function to be called when the Perceptor produces output data. Defaults to None . multi ( bool ): Whether or not to run the perceptor for each item in input data. Defaults to False . accelerator_idx ( int ): The index of the Edge TPU to be used by the Perceptor. Defaults to None . default_config ( dict ): The default configuration for the Perceptor. Defaults to None . Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.add_perceptor_before(name=\"perceptor\", ... name_to_insert_before=\"child_input_stream\", ... perceptor=MyPerceptor(), ... input_callback=None, ... output_callback=None, ... multi=True, ... accelerator_idx=0, ... default_config={\"key\": \"value\"})","title":"add_perceptor_before"},{"location":"pipeline/#add_perceptor_after","text":"def add_perceptor_after(name_to_insert_after: str, name: str, perceptor: Perceptor, input_callback: Callable[[StreamData, PerceptionObjectModel, ConfigRegistry], Any] = None, output_callback: Callable[[Any, PerceptionObjectModel, ConfigRegistry], Any] = None, multi: bool = False, accelerator_idx: Union[int, None] = None, default_config: dict = None) -> None [view_source] Adds a new Perceptor to the pipeline. Arguments name_to_insert_after ( str ): The name of the Perceptor to insert the new Perceptor after. name ( str ): The name of the Perceptor. perceptor ( Perceptor ): The Perceptor to be added. input_callback ( Callable[[StreamData, PerceptionObjectModel, Any], ConfigRegistry] ): The callback function to be called when the Perceptor receives input data. Defaults to None . output_callback ( Callable[[Any, PerceptionObjectModel, ConfigRegistry], Any] ): The callback function to be called when the Perceptor produces output data. Defaults to None . multi ( bool ): Whether or not to run the perceptor for each item in input data. Defaults to False . accelerator_idx ( int ): The index of the Edge TPU to be used by the Perceptor. Defaults to None . default_config ( dict ): The default configuration for the Perceptor. Defaults to None . Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.add_perceptor_after(name=\"perceptor\", ... name_to_insert_after=\"parent_input_stream\", ... perceptor=MyPerceptor(), ... input_callback=None, ... output_callback=None, ... multi=True, ... accelerator_idx=0, ... default_config={\"key\": \"value\"})","title":"add_perceptor_after"},{"location":"pipeline/#add_parallel_perceptor","text":"def add_parallel_perceptor(name_to_insert_in_parallel_with: str, name: str, perceptor: Perceptor, input_callback: Callable[[StreamData, PerceptionObjectModel, ConfigRegistry], Any] = None, output_callback: Callable[[Any, PerceptionObjectModel, ConfigRegistry], Any] = None, multi: bool = False, accelerator_idx: Union[int, None] = None, default_config: dict = None) -> None [view_source] Adds a new Perceptor to the pipeline. Arguments name_to_insert_in_parallel_with ( str ): The name of the Perceptor to insert the new Perceptor in parallel with. name ( str ): The name of the Perceptor. perceptor ( Perceptor ): The Perceptor to be added. input_callback ( Callable[[StreamData, PerceptionObjectModel, ConfigRegistry], Any] ): The callback function to be called when the Perceptor receives input data. Defaults to None . output_callback ( Callable[[Any, PerceptionObjectModel, ConfigRegistry], Any] ): The callback function to be called when the Perceptor produces output data. Defaults to None . multi ( bool ): Whether or not to run the perceptor for each item in input data. Defaults to False . accelerator_idx ( int ): The index of the Edge TPU to be used by the Perceptor. Defaults to None . default_config ( dict ): The default configuration for the Perceptor. Defaults to None . Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.add_parallel_perceptor(name=\"perceptor\", ... name_to_insert_in_parallel_with=\"parallel_input_stream\", ... perceptor=MyPerceptor(), ... input_callback=None, ... output_callback=None, ... multi=True, ... accelerator_idx=0, ... default_config={\"key\": \"value\"})","title":"add_parallel_perceptor"},{"location":"pipeline/#update_input_stream","text":"def update_input_stream(input_stream: InputStream) -> None [view_source] Updates the input stream of the pipeline. Arguments input_stream ( InputStream ): The input stream to be added. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.update_input_stream(camera) <a id=\"darcyai.pipeline.Pipeline.add_output_stream\"></a> #### add\\_output\\_stream ```python def add_output_stream(name: str, callback: Callable[[PerceptionObjectModel, StreamData], Any], output_stream: OutputStream, default_config: dict = None) -> None [view_source] Adds an OutputStream to the pipeline. Arguments name ( str ): The name of the OutputStream. callback ( Callable[[PerceptionObjectModel, StreamData], Any] ): A callback function that is called whith PerceptionObjectModel object and returns the data that the output stream must process. output_stream ( OutputStream ): The OutputStream to be added. default_config ( dict ): The default configuration for the OutputStream. Defaults to None . Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.add_output_stream(name=\"output_stream\", ... callback=None, ... output_stream=MyOutputStream(), ... default_config={\"key\": \"value\"})","title":"update_input_stream"},{"location":"pipeline/#remove_output_stream","text":"def remove_output_stream(name: str) -> None [view_source] Removes an OutputStream from the pipeline. Arguments name ( str ): The name of the OutputStream to be removed. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera)\\ >>> pipeline.add_output_stream(name=\"output_stream\", ... callback=None, ... output_stream=MyOutputStream(), ... default_config={\"key\": \"value\"}) >>> pipeline.remove_output_stream(name=\"output_stream\")","title":"remove_output_stream"},{"location":"pipeline/#stop","text":"def stop() -> None [view_source] Stops the pipeline. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.stop()","title":"stop"},{"location":"pipeline/#run","text":"def run() -> None [view_source] Runs the pipeline. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.run()","title":"run"},{"location":"pipeline/#get_pom","text":"def get_pom() -> PerceptionObjectModel [view_source] Gets the Perception Object Model. Returns PerceptionObjectModel : The Perception Object Model. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pom = pipeline.get_pom()","title":"get_pom"},{"location":"pipeline/#get_current_pulse_number","text":"def get_current_pulse_number() -> int [view_source] Gets the current pulse number. Returns int : The current pulse number. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pulse_number = pipeline.get_current_pulse_number()","title":"get_current_pulse_number"},{"location":"pipeline/#get_latest_input","text":"def get_latest_input() -> StreamData [view_source] Gets the latest input data. Returns StreamData : The latest input data. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> latest_input = pipeline.get_latest_input()","title":"get_latest_input"},{"location":"pipeline/#get_historical_input","text":"def get_historical_input(pulse_number: int) -> StreamData [view_source] Gets the input data from the history. Arguments pulse_number ( int ): The pulse number. Returns StreamData : The input data from the history. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> historical_input = pipeline.get_historical_input(pulse_number=1)","title":"get_historical_input"},{"location":"pipeline/#get_input_history","text":"def get_input_history() -> Dict[int, StreamData] [view_source] Gets the input data history. Returns Dict[int, StreamData] - The input data history. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> input_history = pipeline.get_input_history()","title":"get_input_history"},{"location":"pipeline/#get_historical_pom","text":"def get_historical_pom(pulse_number: int) -> PerceptionObjectModel [view_source] Gets the POM from the history. Arguments pulse_number ( int ): The pulse number. Returns PerceptionObjectModel : The POM from the history. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> historical_pom = pipeline.get_historical_pom(pulse_number=1)","title":"get_historical_pom"},{"location":"pipeline/#get_pom_history","text":"def get_pom_history() -> Dict[int, PerceptionObjectModel] [view_source] Gets the POM history. Returns Dict[int, PerceptionObjectModel] - The POM history. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pom_history = pipeline.get_pom_history()","title":"get_pom_history"},{"location":"pipeline/#run_perceptor","text":"def run_perceptor(perceptor: Perceptor, input_data: Any, multi: bool = False) -> Any [view_source] Runs the Perceptor. Arguments perceptor ( Perceptor ): The Perceptor to be run. input_data ( Any ): The input data. multi ( bool ): Whether or not to run the perceptor for each item in input data. Defaults to False . Returns Any : The result of running the Perceptor. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> result = pipeline.run_perceptor(perceptor=Perceptor(), input_data=None, multi=True)","title":"run_perceptor"},{"location":"pipeline/#get_graph","text":"def get_graph() -> Any [view_source] Gets the graph of the perceptors. Returns Any : The graph of the perceptors. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> graph = pipeline.get_graph()","title":"get_graph"},{"location":"pipeline/#get_all_performance_metrics","text":"def get_all_performance_metrics() -> Dict[str, Any] [view_source] Gets the performance metrics of the pipeline. Returns Dict[str, Any] - The performance metrics of the pipeline. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> metrics = pipeline.get_all_performance_metrics()","title":"get_all_performance_metrics"},{"location":"pipeline/#get_pulse_performance_metrics","text":"def get_pulse_performance_metrics(pulse_number: Union[int, None] = None) -> Dict[str, Any] [view_source] Gets the performance metrics of the pipeline for specific pulse. Arguments pulse_number ( int ): The pulse number of the pulse. Defaults to current pulse. Defaults to None . Returns Dict[str, Any] - The performance metrics of the pipeline for specific pulse. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> metrics = pipeline.get_pulse_performance_metrics(pulse_number=1)","title":"get_pulse_performance_metrics"},{"location":"pipeline/#get_perceptor_performance_metrics","text":"def get_perceptor_performance_metrics(name: str, pulse_number: Union[int, None] = None) -> Dict[str, Any] [view_source] Gets the performance metrics of the pipeline for specific perceptor. Arguments name ( str ): The name of the perceptor. pulse_number ( int ): The pulse number of the pulse. Defaults to current pulse. Defaults to None . Returns Dict[str, Any] - The performance metrics of the pipeline for specific perceptor. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> metrics = pipeline.get_perceptor_performance_metrics(name=\"perceptor_name\", ... pulse_number=1)","title":"get_perceptor_performance_metrics"},{"location":"pipeline/#set_perceptor_config","text":"def set_perceptor_config(perceptor_name: str, name: str, value: Any) -> None [view_source] Sets the config of the pipeline. Arguments perceptor_name ( str ): The name of the perceptor. name ( str ): The name of the config. value ( Any ): The value of the config. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.set_perceptor_config(perceptor_name=\"perceptor_name\", ... name=\"config_name\", ... value=1)","title":"set_perceptor_config"},{"location":"pipeline/#get_perceptor_config","text":"def get_perceptor_config(perceptor_name: str) -> Dict[str, Tuple[Any, Config]] [view_source] Gets the config of the perceptor. Arguments perceptor_name ( str ): The name of the perceptor. Returns Dict[str, Tuple[Any, Config]] - The config of the perceptor. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> config = pipeline.get_perceptor_config(perceptor_name=\"perceptor_name\")","title":"get_perceptor_config"},{"location":"pipeline/#set_output_stream_config","text":"def set_output_stream_config(name: str, config_name: str, value: Any) -> None [view_source] Sets the config of the output stream. Arguments name ( str ): The name of the output stream. config_name ( str ): The name of the config. value ( Any ): The value of the config. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> pipeline.set_output_stream_config(name=\"output_stream_name\", ... config_name=\"config_name\", ... value=1)","title":"set_output_stream_config"},{"location":"pipeline/#get_output_stream_config","text":"def get_output_stream_config(name: str) -> Dict[str, Tuple[Any, Config]] [view_source] Gets the config of the output stream. Arguments name ( str ): The name of the output stream. Returns Dict[str, Tuple[Any, Config]] - The config of the output stream. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.pipeline import Pipeline >>> camera = CameraStream(video_device=\"/dev/video0\") >>> pipeline = Pipeline(input_stream=camera) >>> config = pipeline.get_output_stream_config(name=\"output_stream_name\")","title":"get_output_stream_config"},{"location":"serializable/","text":"darcyai.serializable [view_source] Serializable Objects class Serializable() [view_source] Base class for all serializable objects. serialize def serialize() -> Dict[str, Any] [view_source] Serializes the object into a dictionary. Returns Dict[str, Any] - The serialized object.","title":"Serializable"},{"location":"serializable/#darcyaiserializable","text":"[view_source]","title":"darcyai.serializable"},{"location":"serializable/#serializable-objects","text":"class Serializable() [view_source] Base class for all serializable objects.","title":"Serializable Objects"},{"location":"serializable/#serialize","text":"def serialize() -> Dict[str, Any] [view_source] Serializes the object into a dictionary. Returns Dict[str, Any] - The serialized object.","title":"serialize"},{"location":"streamdata/","text":"darcyai.stream_data [view_source] StreamData Objects class StreamData(Serializable) [view_source] Class to hold data from a stream. Arguments data ( Any ): The data to be stored. timestamp ( int ): The timestamp of the data. serialize def serialize() -> dict [view_source] Serializes the data. Returns dict : The serialized data.","title":"StreamData"},{"location":"streamdata/#darcyaistream_data","text":"[view_source]","title":"darcyai.stream_data"},{"location":"streamdata/#streamdata-objects","text":"class StreamData(Serializable) [view_source] Class to hold data from a stream. Arguments data ( Any ): The data to be stored. timestamp ( int ): The timestamp of the data.","title":"StreamData Objects"},{"location":"streamdata/#serialize","text":"def serialize() -> dict [view_source] Serializes the data. Returns dict : The serialized data.","title":"serialize"},{"location":"coral-perceptors/imageclassificationperceptor/","text":"darcyai.perceptor.coral.image_classification_perceptor [view_source] ImageClassificationPerceptor Objects class ImageClassificationPerceptor(CoralPerceptorBase) [view_source] ImageClassificationPerceptor is a class that implements the Perceptor interface for image classification. Arguments : threshold float - The threshold for object detection. top_k int - The number of top predictions to return. labels_file str - The path to the labels file. labels dict - A dictionary of labels. mean float - The mean of the image. std float - The standard deviation of the image. **kwargs - Keyword arguments to pass to Perceptor. run def run(input_data: Any, config: ConfigRegistry = None) -> (List[Any], List[str]) [view_source] Runs the image classification model. Arguments : input_data Any - The input data to run the model on. config ConfigRegistry - The configuration for the perceptor. Returns : (list[Any], list(str)): A tuple containing the detected classes and the labels. load def load(accelerator_idx: [int, None]) -> None [view_source] Loads the image classification model. Arguments : accelerator_idx int - The index of the Edge TPU to use. Returns : None","title":"ImageClassificationPerceptor"},{"location":"coral-perceptors/imageclassificationperceptor/#darcyaiperceptorcoralimage_classification_perceptor","text":"[view_source]","title":"darcyai.perceptor.coral.image_classification_perceptor"},{"location":"coral-perceptors/imageclassificationperceptor/#imageclassificationperceptor-objects","text":"class ImageClassificationPerceptor(CoralPerceptorBase) [view_source] ImageClassificationPerceptor is a class that implements the Perceptor interface for image classification. Arguments : threshold float - The threshold for object detection. top_k int - The number of top predictions to return. labels_file str - The path to the labels file. labels dict - A dictionary of labels. mean float - The mean of the image. std float - The standard deviation of the image. **kwargs - Keyword arguments to pass to Perceptor.","title":"ImageClassificationPerceptor Objects"},{"location":"coral-perceptors/imageclassificationperceptor/#run","text":"def run(input_data: Any, config: ConfigRegistry = None) -> (List[Any], List[str]) [view_source] Runs the image classification model. Arguments : input_data Any - The input data to run the model on. config ConfigRegistry - The configuration for the perceptor. Returns : (list[Any], list(str)): A tuple containing the detected classes and the labels.","title":"run"},{"location":"coral-perceptors/imageclassificationperceptor/#load","text":"def load(accelerator_idx: [int, None]) -> None [view_source] Loads the image classification model. Arguments : accelerator_idx int - The index of the Edge TPU to use. Returns : None","title":"load"},{"location":"coral-perceptors/objectdetectionperceptor/","text":"darcyai.perceptor.coral.object_detection_perceptor [view_source] ObjectDetectionPerceptor Objects class ObjectDetectionPerceptor(CoralPerceptorBase) [view_source] ObjectDetectionPerceptor is a class that implements the Perceptor interface for object detection. Arguments : threshold float - The threshold for object detection. labels_file str - The path to the labels file. **kwargs - Keyword arguments to pass to Perceptor. run def run(input_data: Any, config: ConfigRegistry = None) -> (List[Any], List[str]) [view_source] Runs the object detection model on the input data. Arguments : input_data Any - The input data to run the model on. config ConfigRegistry - The configuration for the Perceptor. Returns : (list[Any], list(str)): A tuple containing the detected objects and the labels. load def load(accelerator_idx: [int, None]) -> None [view_source] Loads the object detection model. Arguments : accelerator_idx int - The index of the Edge TPU to use. Returns : None","title":"ObjectDetectionPerceptor"},{"location":"coral-perceptors/objectdetectionperceptor/#darcyaiperceptorcoralobject_detection_perceptor","text":"[view_source]","title":"darcyai.perceptor.coral.object_detection_perceptor"},{"location":"coral-perceptors/objectdetectionperceptor/#objectdetectionperceptor-objects","text":"class ObjectDetectionPerceptor(CoralPerceptorBase) [view_source] ObjectDetectionPerceptor is a class that implements the Perceptor interface for object detection. Arguments : threshold float - The threshold for object detection. labels_file str - The path to the labels file. **kwargs - Keyword arguments to pass to Perceptor.","title":"ObjectDetectionPerceptor Objects"},{"location":"coral-perceptors/objectdetectionperceptor/#run","text":"def run(input_data: Any, config: ConfigRegistry = None) -> (List[Any], List[str]) [view_source] Runs the object detection model on the input data. Arguments : input_data Any - The input data to run the model on. config ConfigRegistry - The configuration for the Perceptor. Returns : (list[Any], list(str)): A tuple containing the detected objects and the labels.","title":"run"},{"location":"coral-perceptors/objectdetectionperceptor/#load","text":"def load(accelerator_idx: [int, None]) -> None [view_source] Loads the object detection model. Arguments : accelerator_idx int - The index of the Edge TPU to use. Returns : None","title":"load"},{"location":"coral-perceptors/peopleperceptor/","text":"darcyai.perceptor.coral.people_perceptor [view_source] KeypointType Objects class KeypointType(enum.IntEnum) [view_source] Pose kepoints. PoseEngine Objects class PoseEngine() [view_source] Engine used for pose tasks. __init__ def __init__(model_path, mirror=False, arch=os.uname().machine) [view_source] Creates a PoseEngine with given model. Arguments : model_path - String, path to TF-Lite Flatbuffer file. mirror - Flip keypoints horizontally. Raises : ValueError - An error occurred when model output is invalid. run_inference def run_inference(input_data) [view_source] Run inference using the zero copy feature from pycoral and returns inference time in ms. DetectPosesInImage def DetectPosesInImage(img) [view_source] Detects poses in a given image. For ideal results make sure the image fed to this function is close to the expected input size - it is the caller's responsibility to resize the image accordingly. Arguments : img - numpy array containing image get_input_tensor_shape def get_input_tensor_shape() [view_source] Returns input tensor shape. get_output_tensor def get_output_tensor(idx) [view_source] Returns output tensor view. ParseOutput def ParseOutput() [view_source] Parses interpreter output tensors and returns decoded poses.","title":"PeoplePerceptor"},{"location":"coral-perceptors/peopleperceptor/#darcyaiperceptorcoralpeople_perceptor","text":"[view_source]","title":"darcyai.perceptor.coral.people_perceptor"},{"location":"coral-perceptors/peopleperceptor/#keypointtype-objects","text":"class KeypointType(enum.IntEnum) [view_source] Pose kepoints.","title":"KeypointType Objects"},{"location":"coral-perceptors/peopleperceptor/#poseengine-objects","text":"class PoseEngine() [view_source] Engine used for pose tasks.","title":"PoseEngine Objects"},{"location":"coral-perceptors/peopleperceptor/#__init__","text":"def __init__(model_path, mirror=False, arch=os.uname().machine) [view_source] Creates a PoseEngine with given model. Arguments : model_path - String, path to TF-Lite Flatbuffer file. mirror - Flip keypoints horizontally. Raises : ValueError - An error occurred when model output is invalid.","title":"__init__"},{"location":"coral-perceptors/peopleperceptor/#run_inference","text":"def run_inference(input_data) [view_source] Run inference using the zero copy feature from pycoral and returns inference time in ms.","title":"run_inference"},{"location":"coral-perceptors/peopleperceptor/#detectposesinimage","text":"def DetectPosesInImage(img) [view_source] Detects poses in a given image. For ideal results make sure the image fed to this function is close to the expected input size - it is the caller's responsibility to resize the image accordingly. Arguments : img - numpy array containing image","title":"DetectPosesInImage"},{"location":"coral-perceptors/peopleperceptor/#get_input_tensor_shape","text":"def get_input_tensor_shape() [view_source] Returns input tensor shape.","title":"get_input_tensor_shape"},{"location":"coral-perceptors/peopleperceptor/#get_output_tensor","text":"def get_output_tensor(idx) [view_source] Returns output tensor view.","title":"get_output_tensor"},{"location":"coral-perceptors/peopleperceptor/#parseoutput","text":"def ParseOutput() [view_source] Parses interpreter output tensors and returns decoded poses.","title":"ParseOutput"},{"location":"coral-perceptors/peoplepom/","text":"darcyai.perceptor.coral.people_perceptor_pom [view_source]","title":"PeoplePOM"},{"location":"coral-perceptors/peoplepom/#darcyaiperceptorcoralpeople_perceptor_pom","text":"[view_source]","title":"darcyai.perceptor.coral.people_perceptor_pom"},{"location":"input-streams/camerastream/","text":"darcyai.input.camera_stream [view_source] CameraStream Objects class CameraStream(InputStream) [view_source] An input stream that gets frames from camera. Arguments use_pi_camera ( bool ): Whether or not to use the Raspberry Pi camera. Defaults to False . video_device ( str ): The video device to use. Defaults to None . video_width ( int ): The width of the video frames. Defaults to 640 . video_height ( int ): The height of the video frames. Defaults to 480 . flip_frames ( bool ): Whether or not to flip the video frames. Defaults to False . fps ( int ): The frames per second to stream. Defaults to 30 . Examples >>> from darcyai.input.camera_stream import CameraStream >>> pi_camera = CameraStream(use_pi_camera=True) >>> usb_camera = CameraStream(video_device=\"/dev/video0\") stop def stop() -> None [view_source] Stops the video stream. Examples >>> from darcyai.input.camera_stream import CameraStream >>> usb_camera = CameraStream(video_device=\"/dev/video0\") >>> usb_camera.stop() stream def stream() -> Iterable[VideoStreamData] [view_source] Streams the video frames. Returns An iterable of VideoStreamData objects. Examples >>> from darcyai.input.camera_stream import CameraStream >>> usb_camera = CameraStream(video_device=\"/dev/video0\") >>> usb_camera.stream()","title":"CameraStream"},{"location":"input-streams/camerastream/#darcyaiinputcamera_stream","text":"[view_source]","title":"darcyai.input.camera_stream"},{"location":"input-streams/camerastream/#camerastream-objects","text":"class CameraStream(InputStream) [view_source] An input stream that gets frames from camera. Arguments use_pi_camera ( bool ): Whether or not to use the Raspberry Pi camera. Defaults to False . video_device ( str ): The video device to use. Defaults to None . video_width ( int ): The width of the video frames. Defaults to 640 . video_height ( int ): The height of the video frames. Defaults to 480 . flip_frames ( bool ): Whether or not to flip the video frames. Defaults to False . fps ( int ): The frames per second to stream. Defaults to 30 . Examples >>> from darcyai.input.camera_stream import CameraStream >>> pi_camera = CameraStream(use_pi_camera=True) >>> usb_camera = CameraStream(video_device=\"/dev/video0\")","title":"CameraStream Objects"},{"location":"input-streams/camerastream/#stop","text":"def stop() -> None [view_source] Stops the video stream. Examples >>> from darcyai.input.camera_stream import CameraStream >>> usb_camera = CameraStream(video_device=\"/dev/video0\") >>> usb_camera.stop()","title":"stop"},{"location":"input-streams/camerastream/#stream","text":"def stream() -> Iterable[VideoStreamData] [view_source] Streams the video frames. Returns An iterable of VideoStreamData objects. Examples >>> from darcyai.input.camera_stream import CameraStream >>> usb_camera = CameraStream(video_device=\"/dev/video0\") >>> usb_camera.stream()","title":"stream"},{"location":"input-streams/inputmultistream/","text":"darcyai.input.input_multi_stream [view_source] InputMultiStream Objects class InputMultiStream() [view_source] A class that represents a collection of input streams. Arguments aggregator ( Callable[[None], StreamData] ): a function that takes a list of data and returns a single data point callback ( Callable[[StreamData], None] ): a function that gets called when data is received from a stream Examples >>> from darcyai.input.input_multi_stream import InputMultiStream >>> from darcyai.stream_data import StreamData >>> def aggregator(): ... return StreamData(\"data\", 1234567890) >>> def callback(data: StreamData): ... print(data.data, data.timestamp) >>> input_stream = InputMultiStream(aggregator, callback) remove_stream def remove_stream(name: str) -> None [view_source] Removes a stream from the collection. Arguments name ( str ): the name of the stream to remove Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.input.input_multi_stream import InputMultiStream >>> usb_camera = CameraStream(video_device=\"/dev/video0\") >>> input_stream = InputMultiStream(aggregator, callback) >>> input_stream.add_stream(\"usb_camera\", usb_camera) >>> input_stream.remove_stream(\"usb_camera\") get_stream def get_stream(name: str) -> InputStream [view_source] Gets a stream from the collection. Arguments name ( str ): the name of the stream to get Returns InputStream : the stream with the given name Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.input.input_multi_stream import InputMultiStream >>> usb_camera = CameraStream(video_device=\"/dev/video0\") >>> input_stream = InputMultiStream(aggregator, callback) >>> input_stream.add_stream(\"usb_camera\", usb_camera) >>> input_stream.get_stream(\"usb_camera\") add_stream def add_stream(name: str, stream: InputStream) -> None [view_source] Adds a stream to the collection. Arguments name ( str ): the name of the stream to add stream ( InputStream ): the stream to add Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.input.input_multi_stream import InputMultiStream >>> usb_camera = CameraStream(video_device=\"/dev/video0\") >>> input_stream = InputMultiStream(aggregator, callback) >>> input_stream.add_stream(\"usb_camera\", usb_camera) stream def stream() -> Iterable[StreamData] [view_source] Starts streaming data from all streams in the collection. Returns Iterable[StreamData] : an iterable of data from all streams Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.input.input_multi_stream import InputMultiStream >>> usb_camera = CameraStream(video_device=\"/dev/video0\") >>> input_stream = InputMultiStream(aggregator, callback) >>> input_stream.add_stream(\"usb_camera\", usb_camera) >>> input_stream.stream() stop def stop() -> None [view_source] Stops streaming data from all streams in the collection. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.input.input_multi_stream import InputMultiStream >>> usb_camera = CameraStream(video_device=\"/dev/video0\") >>> input_stream = InputMultiStream(aggregator, callback) >>> input_stream.add_stream(\"usb_camera\", usb_camera) >>> input_stream.stop()","title":"InputMultiStream"},{"location":"input-streams/inputmultistream/#darcyaiinputinput_multi_stream","text":"[view_source]","title":"darcyai.input.input_multi_stream"},{"location":"input-streams/inputmultistream/#inputmultistream-objects","text":"class InputMultiStream() [view_source] A class that represents a collection of input streams. Arguments aggregator ( Callable[[None], StreamData] ): a function that takes a list of data and returns a single data point callback ( Callable[[StreamData], None] ): a function that gets called when data is received from a stream Examples >>> from darcyai.input.input_multi_stream import InputMultiStream >>> from darcyai.stream_data import StreamData >>> def aggregator(): ... return StreamData(\"data\", 1234567890) >>> def callback(data: StreamData): ... print(data.data, data.timestamp) >>> input_stream = InputMultiStream(aggregator, callback)","title":"InputMultiStream Objects"},{"location":"input-streams/inputmultistream/#remove_stream","text":"def remove_stream(name: str) -> None [view_source] Removes a stream from the collection. Arguments name ( str ): the name of the stream to remove Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.input.input_multi_stream import InputMultiStream >>> usb_camera = CameraStream(video_device=\"/dev/video0\") >>> input_stream = InputMultiStream(aggregator, callback) >>> input_stream.add_stream(\"usb_camera\", usb_camera) >>> input_stream.remove_stream(\"usb_camera\")","title":"remove_stream"},{"location":"input-streams/inputmultistream/#get_stream","text":"def get_stream(name: str) -> InputStream [view_source] Gets a stream from the collection. Arguments name ( str ): the name of the stream to get Returns InputStream : the stream with the given name Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.input.input_multi_stream import InputMultiStream >>> usb_camera = CameraStream(video_device=\"/dev/video0\") >>> input_stream = InputMultiStream(aggregator, callback) >>> input_stream.add_stream(\"usb_camera\", usb_camera) >>> input_stream.get_stream(\"usb_camera\")","title":"get_stream"},{"location":"input-streams/inputmultistream/#add_stream","text":"def add_stream(name: str, stream: InputStream) -> None [view_source] Adds a stream to the collection. Arguments name ( str ): the name of the stream to add stream ( InputStream ): the stream to add Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.input.input_multi_stream import InputMultiStream >>> usb_camera = CameraStream(video_device=\"/dev/video0\") >>> input_stream = InputMultiStream(aggregator, callback) >>> input_stream.add_stream(\"usb_camera\", usb_camera)","title":"add_stream"},{"location":"input-streams/inputmultistream/#stream","text":"def stream() -> Iterable[StreamData] [view_source] Starts streaming data from all streams in the collection. Returns Iterable[StreamData] : an iterable of data from all streams Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.input.input_multi_stream import InputMultiStream >>> usb_camera = CameraStream(video_device=\"/dev/video0\") >>> input_stream = InputMultiStream(aggregator, callback) >>> input_stream.add_stream(\"usb_camera\", usb_camera) >>> input_stream.stream()","title":"stream"},{"location":"input-streams/inputmultistream/#stop","text":"def stop() -> None [view_source] Stops streaming data from all streams in the collection. Examples >>> from darcyai.input.camera_stream import CameraStream >>> from darcyai.input.input_multi_stream import InputMultiStream >>> usb_camera = CameraStream(video_device=\"/dev/video0\") >>> input_stream = InputMultiStream(aggregator, callback) >>> input_stream.add_stream(\"usb_camera\", usb_camera) >>> input_stream.stop()","title":"stop"},{"location":"input-streams/inputstream/","text":"darcyai.input.input_stream [view_source] InputStream Objects class InputStream() [view_source] Base class for reading input from a stream. Examples >>> from darcyai.input.input_stream import InputStream >>> from darcyai.stream_data import StreamData >>> class MyInputStream(InputStream): ... def stream(self): ... yield StreamData(\"data\", 1234567890) >>> def stop(self): ... pass stream def stream() -> Iterable[StreamData] [view_source] Returns a generator that yields a stream of input. Returns A generator that yields a stream of input. stop def stop() -> None [view_source] Stops the stream.","title":"InputStream"},{"location":"input-streams/inputstream/#darcyaiinputinput_stream","text":"[view_source]","title":"darcyai.input.input_stream"},{"location":"input-streams/inputstream/#inputstream-objects","text":"class InputStream() [view_source] Base class for reading input from a stream. Examples >>> from darcyai.input.input_stream import InputStream >>> from darcyai.stream_data import StreamData >>> class MyInputStream(InputStream): ... def stream(self): ... yield StreamData(\"data\", 1234567890) >>> def stop(self): ... pass","title":"InputStream Objects"},{"location":"input-streams/inputstream/#stream","text":"def stream() -> Iterable[StreamData] [view_source] Returns a generator that yields a stream of input. Returns A generator that yields a stream of input.","title":"stream"},{"location":"input-streams/inputstream/#stop","text":"def stop() -> None [view_source] Stops the stream.","title":"stop"},{"location":"input-streams/videofilestream/","text":"darcyai.input.video_file_stream [view_source] VideoFileStream Objects class VideoFileStream(InputStream) [view_source] An input stream that reads frames from a video file. Arguments file_name ( str ): The name of the video file to stream. use_pi_camera ( bool ): Whether or not to use the Raspberry Pi camera. loop ( bool ): Whether or not to loop the video. Defaults to True . process_all_frames ( bool ): Whether or not to process all frames. Defaults to True . Examples >>> from darcyai.input.video_file_stream import VideoFileStream >>> video_file_stream = VideoFileStream(file_name=\"video.mp4\", loop=True, process_all_frames=True) stop def stop() -> None [view_source] Stops the video stream. Examples >>> from darcyai.input.video_file_stream import VideoFileStream >>> video_file_stream = VideoFileStream(file_name=\"video.mp4\", loop=True, process_all_frames=True) >>> video_file_stream.stop() stream def stream() -> Iterable[VideoStreamData] [view_source] Streams the video frames. Returns An iterable of VideoStreamData objects. Examples >>> from darcyai.input.video_file_stream import VideoFileStream >>> video_file_stream = VideoFileStream(file_name=\"video.mp4\", loop=True, process_all_frames=True) >>> video_file_stream.stream()","title":"VideoFileStream"},{"location":"input-streams/videofilestream/#darcyaiinputvideo_file_stream","text":"[view_source]","title":"darcyai.input.video_file_stream"},{"location":"input-streams/videofilestream/#videofilestream-objects","text":"class VideoFileStream(InputStream) [view_source] An input stream that reads frames from a video file. Arguments file_name ( str ): The name of the video file to stream. use_pi_camera ( bool ): Whether or not to use the Raspberry Pi camera. loop ( bool ): Whether or not to loop the video. Defaults to True . process_all_frames ( bool ): Whether or not to process all frames. Defaults to True . Examples >>> from darcyai.input.video_file_stream import VideoFileStream >>> video_file_stream = VideoFileStream(file_name=\"video.mp4\", loop=True, process_all_frames=True)","title":"VideoFileStream Objects"},{"location":"input-streams/videofilestream/#stop","text":"def stop() -> None [view_source] Stops the video stream. Examples >>> from darcyai.input.video_file_stream import VideoFileStream >>> video_file_stream = VideoFileStream(file_name=\"video.mp4\", loop=True, process_all_frames=True) >>> video_file_stream.stop()","title":"stop"},{"location":"input-streams/videofilestream/#stream","text":"def stream() -> Iterable[VideoStreamData] [view_source] Streams the video frames. Returns An iterable of VideoStreamData objects. Examples >>> from darcyai.input.video_file_stream import VideoFileStream >>> video_file_stream = VideoFileStream(file_name=\"video.mp4\", loop=True, process_all_frames=True) >>> video_file_stream.stream()","title":"stream"},{"location":"input-streams/videostreamdata/","text":"darcyai.input.video_stream_data [view_source] VideoStreamData Objects class VideoStreamData(StreamData) [view_source] StreamData representation of video frames serialize def serialize() -> dict [view_source] Serialize the data to a dict Returns dict : serialized data Examples >>> from darcyai.input.video_stream_data import VideoStreamData >>> data = VideoStreamData(frame, timestamp) >>> data.serialize() { \"frame\": \"base64 encoded frame in jpeg format\", \"timestamp\": 1638482728 }","title":"VideoStreamData"},{"location":"input-streams/videostreamdata/#darcyaiinputvideo_stream_data","text":"[view_source]","title":"darcyai.input.video_stream_data"},{"location":"input-streams/videostreamdata/#videostreamdata-objects","text":"class VideoStreamData(StreamData) [view_source] StreamData representation of video frames","title":"VideoStreamData Objects"},{"location":"input-streams/videostreamdata/#serialize","text":"def serialize() -> dict [view_source] Serialize the data to a dict Returns dict : serialized data Examples >>> from darcyai.input.video_stream_data import VideoStreamData >>> data = VideoStreamData(frame, timestamp) >>> data.serialize() { \"frame\": \"base64 encoded frame in jpeg format\", \"timestamp\": 1638482728 }","title":"serialize"},{"location":"output-streams/csvoutputstream/","text":"darcyai.output.csv_output_stream [view_source] CSVOutputStream Objects class CSVOutputStream(OutputStream) [view_source] OutputStream implementation that writes to a CSV file. Arguments file_path ( str ): The path to the CSV file to write to. delimiter ( str ): The delimiter to use in the CSV file. Defaults to , . quotechar ( str ): The quote character to use in the CSV file. Defaults to | . buffer_size ( int ): The size of the buffer to use when writing to theCSV file. Defaults to 0 . flush_interval ( int ): The number of seconds before flushing the buffer to disk. Defaults to 0 . Examples >>> from darcyai.output.csv_output_stream import CSVOutputStream >>> csv_output_stream = CSVOutputStream(file_path=\"output.csv\", delimiter=\",\", quotechar=\"|\", buffer_size=1024*1024, flush_interval=0) write def write(data: list) -> None [view_source] Writes the given data to the CSV file. Arguments data ( list ): The data to write to the CSV file. Examples >>> from darcyai.output.csv_output_stream import CSVOutputStream >>> csv_output_stream = CSVOutputStream(file_path=\"output.csv\", delimiter=\",\", quotechar=\"|\", buffer_size=1024*1024, flush_interval=0) >>> csv_output_stream.write([[\"a\", \"b\", \"c\"], [\"d\", \"e\", \"f\"]]) close def close() -> None [view_source] Closes the CSV file. Examples >>> from darcyai.output.csv_output_stream import CSVOutputStream >>> csv_output_stream = CSVOutputStream(file_path=\"output.csv\", delimiter=\",\", quotechar=\"|\", buffer_size=1024*1024, flush_interval=0) >>> csv_output_stream.close()","title":"CSVOutputStream"},{"location":"output-streams/csvoutputstream/#darcyaioutputcsv_output_stream","text":"[view_source]","title":"darcyai.output.csv_output_stream"},{"location":"output-streams/csvoutputstream/#csvoutputstream-objects","text":"class CSVOutputStream(OutputStream) [view_source] OutputStream implementation that writes to a CSV file. Arguments file_path ( str ): The path to the CSV file to write to. delimiter ( str ): The delimiter to use in the CSV file. Defaults to , . quotechar ( str ): The quote character to use in the CSV file. Defaults to | . buffer_size ( int ): The size of the buffer to use when writing to theCSV file. Defaults to 0 . flush_interval ( int ): The number of seconds before flushing the buffer to disk. Defaults to 0 . Examples >>> from darcyai.output.csv_output_stream import CSVOutputStream >>> csv_output_stream = CSVOutputStream(file_path=\"output.csv\", delimiter=\",\", quotechar=\"|\", buffer_size=1024*1024, flush_interval=0)","title":"CSVOutputStream Objects"},{"location":"output-streams/csvoutputstream/#write","text":"def write(data: list) -> None [view_source] Writes the given data to the CSV file. Arguments data ( list ): The data to write to the CSV file. Examples >>> from darcyai.output.csv_output_stream import CSVOutputStream >>> csv_output_stream = CSVOutputStream(file_path=\"output.csv\", delimiter=\",\", quotechar=\"|\", buffer_size=1024*1024, flush_interval=0) >>> csv_output_stream.write([[\"a\", \"b\", \"c\"], [\"d\", \"e\", \"f\"]])","title":"write"},{"location":"output-streams/csvoutputstream/#close","text":"def close() -> None [view_source] Closes the CSV file. Examples >>> from darcyai.output.csv_output_stream import CSVOutputStream >>> csv_output_stream = CSVOutputStream(file_path=\"output.csv\", delimiter=\",\", quotechar=\"|\", buffer_size=1024*1024, flush_interval=0) >>> csv_output_stream.close()","title":"close"},{"location":"output-streams/jsonoutputstream/","text":"darcyai.output.json_output_stream [view_source] JSONOutputStream Objects class JSONOutputStream(OutputStream) [view_source] OutputStream implementation that writes to a JSON file. Arguments file_path ( str ): The path to the JSON file to write to. buffer_size ( int ): The size of the buffer to use when writing to the JSON file. Defaults to 0 . flush_interval ( int ): The number of seconds before flushing the buffer to disk. Defaults to 0 . Examples >>> from darcyai.output.json_output_stream import JSONOutputStream >>> json_output_stream = JSONOutputStream(file_path=\"output.csv\", buffer_size=0) write def write(data: dict) -> None [view_source] Writes the given data to the JSON file. Arguments data ( dict ): The data to write to the JSON file. Examples >>> from darcyai.output.json_output_stream import JSONOutputStream >>> json_output_stream = JSONOutputStream(file_path=\"output.csv\", buffer_size=0) >>> json_output_stream.write({\"key\": \"value\"}) close def close() -> None [view_source] Closes the JSON file. Examples >>> from darcyai.output.json_output_stream import JSONOutputStream >>> json_output_stream = JSONOutputStream(file_path=\"output.csv\", buffer_size=0) >>> json_output_stream.close()","title":"JSONOutputStream"},{"location":"output-streams/jsonoutputstream/#darcyaioutputjson_output_stream","text":"[view_source]","title":"darcyai.output.json_output_stream"},{"location":"output-streams/jsonoutputstream/#jsonoutputstream-objects","text":"class JSONOutputStream(OutputStream) [view_source] OutputStream implementation that writes to a JSON file. Arguments file_path ( str ): The path to the JSON file to write to. buffer_size ( int ): The size of the buffer to use when writing to the JSON file. Defaults to 0 . flush_interval ( int ): The number of seconds before flushing the buffer to disk. Defaults to 0 . Examples >>> from darcyai.output.json_output_stream import JSONOutputStream >>> json_output_stream = JSONOutputStream(file_path=\"output.csv\", buffer_size=0)","title":"JSONOutputStream Objects"},{"location":"output-streams/jsonoutputstream/#write","text":"def write(data: dict) -> None [view_source] Writes the given data to the JSON file. Arguments data ( dict ): The data to write to the JSON file. Examples >>> from darcyai.output.json_output_stream import JSONOutputStream >>> json_output_stream = JSONOutputStream(file_path=\"output.csv\", buffer_size=0) >>> json_output_stream.write({\"key\": \"value\"})","title":"write"},{"location":"output-streams/jsonoutputstream/#close","text":"def close() -> None [view_source] Closes the JSON file. Examples >>> from darcyai.output.json_output_stream import JSONOutputStream >>> json_output_stream = JSONOutputStream(file_path=\"output.csv\", buffer_size=0) >>> json_output_stream.close()","title":"close"},{"location":"output-streams/livefeedstream/","text":"darcyai.output.live_feed_stream [view_source] LiveFeedStream Objects class LiveFeedStream(OutputStream) [view_source] An output stream that streams the frames. Arguments path ( str ): Path to host the live stream. flask_app ( Flask ): Flask app to host the live stream. Defaults to None . port ( int ): Port to host the live stream. Defaults to None . host ( str ): Host to host the live stream. Defaults to None . fps ( int ): Frames per second to stream. Defaults to 20 . quality ( int ): Quality of the JPEG encoding. Defaults to 100 . Examples >>> from darcyai.output.live_feed_stream import LiveFeedStream >>> live_feed_stream = LiveFeedStream(path=\"/live-feed\", >>> port=8080, >>> host=\"0.0.0.0\", >>> fps=20, >>> quality=100) write def write(data: Any) -> Any [view_source] Write a frame to the stream. Arguments data ( Any ): Frame to write. Returns Any : The annotated frame. Examples >>> from darcyai.output.live_feed_stream import LiveFeedStream >>> live_feed_stream = LiveFeedStream(path=\"/live-feed\", >>> port=8080, >>> host=\"0.0.0.0\", >>> fps=20, >>> quality=100) >>> live_feed_stream.write(frame) get_fps def get_fps() -> int [view_source] Get the frames per second. Returns int : Frames per second. Examples >>> from darcyai.output.live_feed_stream import LiveFeedStream >>> live_feed_stream = LiveFeedStream(path=\"/live-feed\", >>> port=8080, >>> host=\"0.0.0.0\", >>> fps=20, >>> quality=100) >>> live_feed_stream.get_fps() set_fps def set_fps(fps: int) -> None [view_source] Set the frames per second. Arguments fps ( int ): Frames per second. Examples >>> from darcyai.output.live_feed_stream import LiveFeedStream >>> live_feed_stream = LiveFeedStream(path=\"/live-feed\", >>> port=8080, >>> host=\"0.0.0.0\", >>> fps=20, >>> quality=100) >>> live_feed_stream.set_fps(30) get_quality def get_quality() -> int [view_source] Get the quality of the JPEG encoding. Returns int : Quality of the JPEG encoding. Examples >>> from darcyai.output.live_feed_stream import LiveFeedStream >>> live_feed_stream = LiveFeedStream(path=\"/live-feed\", >>> port=8080, >>> host=\"0.0.0.0\", >>> fps=20, >>> quality=100) >>> live_feed_stream.get_quality() set_quality def set_quality(quality: int) -> None [view_source] Set the quality of the JPEG encoding. Arguments quality ( int ): Quality of the JPEG encoding. Examples >>> from darcyai.output.live_feed_stream import LiveFeedStream >>> live_feed_stream = LiveFeedStream(path=\"/live-feed\", >>> port=8080, >>> host=\"0.0.0.0\", >>> fps=20, >>> quality=100) >>> live_feed_stream.set_quality(50) close def close() -> None [view_source] Close the stream. Examples >>> from darcyai.output.live_feed_stream import LiveFeedStream >>> live_feed_stream = LiveFeedStream(path=\"/live-feed\", >>> port=8080, >>> host=\"0.0.0.0\", >>> fps=20, >>> quality=100) >>> live_feed_stream.close() get_latest_frame def get_latest_frame() -> Any [view_source] Returns the latest frame in JPEG format. Returns Any : Latest frame. Examples >>> from darcyai.output.live_feed_stream import LiveFeedStream >>> live_feed_stream = LiveFeedStream(path=\"/live-feed\", >>> port=8080, >>> host=\"0.0.0.0\", >>> fps=20, >>> quality=100) >>> live_feed_stream.get_latest_frame()","title":"LiveFeedStream"},{"location":"output-streams/livefeedstream/#darcyaioutputlive_feed_stream","text":"[view_source]","title":"darcyai.output.live_feed_stream"},{"location":"output-streams/livefeedstream/#livefeedstream-objects","text":"class LiveFeedStream(OutputStream) [view_source] An output stream that streams the frames. Arguments path ( str ): Path to host the live stream. flask_app ( Flask ): Flask app to host the live stream. Defaults to None . port ( int ): Port to host the live stream. Defaults to None . host ( str ): Host to host the live stream. Defaults to None . fps ( int ): Frames per second to stream. Defaults to 20 . quality ( int ): Quality of the JPEG encoding. Defaults to 100 . Examples >>> from darcyai.output.live_feed_stream import LiveFeedStream >>> live_feed_stream = LiveFeedStream(path=\"/live-feed\", >>> port=8080, >>> host=\"0.0.0.0\", >>> fps=20, >>> quality=100)","title":"LiveFeedStream Objects"},{"location":"output-streams/livefeedstream/#write","text":"def write(data: Any) -> Any [view_source] Write a frame to the stream. Arguments data ( Any ): Frame to write. Returns Any : The annotated frame. Examples >>> from darcyai.output.live_feed_stream import LiveFeedStream >>> live_feed_stream = LiveFeedStream(path=\"/live-feed\", >>> port=8080, >>> host=\"0.0.0.0\", >>> fps=20, >>> quality=100) >>> live_feed_stream.write(frame)","title":"write"},{"location":"output-streams/livefeedstream/#get_fps","text":"def get_fps() -> int [view_source] Get the frames per second. Returns int : Frames per second. Examples >>> from darcyai.output.live_feed_stream import LiveFeedStream >>> live_feed_stream = LiveFeedStream(path=\"/live-feed\", >>> port=8080, >>> host=\"0.0.0.0\", >>> fps=20, >>> quality=100) >>> live_feed_stream.get_fps()","title":"get_fps"},{"location":"output-streams/livefeedstream/#set_fps","text":"def set_fps(fps: int) -> None [view_source] Set the frames per second. Arguments fps ( int ): Frames per second. Examples >>> from darcyai.output.live_feed_stream import LiveFeedStream >>> live_feed_stream = LiveFeedStream(path=\"/live-feed\", >>> port=8080, >>> host=\"0.0.0.0\", >>> fps=20, >>> quality=100) >>> live_feed_stream.set_fps(30)","title":"set_fps"},{"location":"output-streams/livefeedstream/#get_quality","text":"def get_quality() -> int [view_source] Get the quality of the JPEG encoding. Returns int : Quality of the JPEG encoding. Examples >>> from darcyai.output.live_feed_stream import LiveFeedStream >>> live_feed_stream = LiveFeedStream(path=\"/live-feed\", >>> port=8080, >>> host=\"0.0.0.0\", >>> fps=20, >>> quality=100) >>> live_feed_stream.get_quality()","title":"get_quality"},{"location":"output-streams/livefeedstream/#set_quality","text":"def set_quality(quality: int) -> None [view_source] Set the quality of the JPEG encoding. Arguments quality ( int ): Quality of the JPEG encoding. Examples >>> from darcyai.output.live_feed_stream import LiveFeedStream >>> live_feed_stream = LiveFeedStream(path=\"/live-feed\", >>> port=8080, >>> host=\"0.0.0.0\", >>> fps=20, >>> quality=100) >>> live_feed_stream.set_quality(50)","title":"set_quality"},{"location":"output-streams/livefeedstream/#close","text":"def close() -> None [view_source] Close the stream. Examples >>> from darcyai.output.live_feed_stream import LiveFeedStream >>> live_feed_stream = LiveFeedStream(path=\"/live-feed\", >>> port=8080, >>> host=\"0.0.0.0\", >>> fps=20, >>> quality=100) >>> live_feed_stream.close()","title":"close"},{"location":"output-streams/livefeedstream/#get_latest_frame","text":"def get_latest_frame() -> Any [view_source] Returns the latest frame in JPEG format. Returns Any : Latest frame. Examples >>> from darcyai.output.live_feed_stream import LiveFeedStream >>> live_feed_stream = LiveFeedStream(path=\"/live-feed\", >>> port=8080, >>> host=\"0.0.0.0\", >>> fps=20, >>> quality=100) >>> live_feed_stream.get_latest_frame()","title":"get_latest_frame"},{"location":"output-streams/outputstream/","text":"darcyai.output.output_stream [view_source] OutputStream Objects class OutputStream(Configurable) [view_source] OutputStream is the base class that is used to write output to a stream. Arguments ignore_none ( bool ): Whether or not to call the endpoint when the data is None. Defaults to True . Examples >>> from darcyai.output.output_stream import OutputStream >>> class MyOutputStream(OutputStream): ... def write(self, data: dict): ... print(data) >>> def close(self): ... pass write def write(data: Any) -> Any [view_source] Processes the data and writes it to the output stream. Arguments data ( Any ): The data to be written to the output stream. Returns Any : The data that was written to the output stream. close def close() -> None [view_source] Closes the output stream. set_config_value def set_config_value(key: str, value: Any) [view_source] Sets a config value. Arguments key ( str ): The key of the config. value ( Any ): The value to set. get_config_value def get_config_value(key: str) -> Any [view_source] Gets a config value. Arguments key ( str ): The key of the config. Returns Any : The value of the config. init_config_registry def init_config_registry() [view_source] Initializes the config registry.","title":"OutputStream"},{"location":"output-streams/outputstream/#darcyaioutputoutput_stream","text":"[view_source]","title":"darcyai.output.output_stream"},{"location":"output-streams/outputstream/#outputstream-objects","text":"class OutputStream(Configurable) [view_source] OutputStream is the base class that is used to write output to a stream. Arguments ignore_none ( bool ): Whether or not to call the endpoint when the data is None. Defaults to True . Examples >>> from darcyai.output.output_stream import OutputStream >>> class MyOutputStream(OutputStream): ... def write(self, data: dict): ... print(data) >>> def close(self): ... pass","title":"OutputStream Objects"},{"location":"output-streams/outputstream/#write","text":"def write(data: Any) -> Any [view_source] Processes the data and writes it to the output stream. Arguments data ( Any ): The data to be written to the output stream. Returns Any : The data that was written to the output stream.","title":"write"},{"location":"output-streams/outputstream/#close","text":"def close() -> None [view_source] Closes the output stream.","title":"close"},{"location":"output-streams/outputstream/#set_config_value","text":"def set_config_value(key: str, value: Any) [view_source] Sets a config value. Arguments key ( str ): The key of the config. value ( Any ): The value to set.","title":"set_config_value"},{"location":"output-streams/outputstream/#get_config_value","text":"def get_config_value(key: str) -> Any [view_source] Gets a config value. Arguments key ( str ): The key of the config. Returns Any : The value of the config.","title":"get_config_value"},{"location":"output-streams/outputstream/#init_config_registry","text":"def init_config_registry() [view_source] Initializes the config registry.","title":"init_config_registry"},{"location":"output-streams/restapistream/","text":"darcyai.output.rest_api_stream [view_source] RestApiStream Objects class RestApiStream(OutputStream) [view_source] A stream that sends data to a REST API. Arguments url ( str ): The URL of the REST API. method ( str ): The HTTP method to use. Must be one of 'POST', 'PUT', 'PATCH'. Defaults to POST . content_type ( str ): The content type of the data. Must be one of 'json' or 'form'. Defaults to json . headers ( dict ): The headers to send with the request. Defaults to None . Examples >>> from darcyai.output.rest_api_stream import RestApiStream >>> rest_api_stream = RestApiStream(url=\"http://localhost:5000/api/v1/data\", method=\"POST\", content_type=\"json\") headers={\"Authorization\": \"Bearer ...\"}) write def write(data: Any) -> Response [view_source] Processes the data and writes it to the output stream. Arguments data ( Any ): The data to be written to the output stream. Returns Response : The response from the REST API. Examples >>> from darcyai.output.rest_api_stream import RestApiStream >>> rest_api_stream = RestApiStream(url=\"http://localhost:5000/api/v1/data\", method=\"POST\", content_type=\"json\") headers={\"Authorization\": \"Bearer ...\"}) >>> response = rest_api_stream.write({\"data\": \"some data\"}) close def close() -> None [view_source] Closes the output stream.","title":"RestApiStream"},{"location":"output-streams/restapistream/#darcyaioutputrest_api_stream","text":"[view_source]","title":"darcyai.output.rest_api_stream"},{"location":"output-streams/restapistream/#restapistream-objects","text":"class RestApiStream(OutputStream) [view_source] A stream that sends data to a REST API. Arguments url ( str ): The URL of the REST API. method ( str ): The HTTP method to use. Must be one of 'POST', 'PUT', 'PATCH'. Defaults to POST . content_type ( str ): The content type of the data. Must be one of 'json' or 'form'. Defaults to json . headers ( dict ): The headers to send with the request. Defaults to None . Examples >>> from darcyai.output.rest_api_stream import RestApiStream >>> rest_api_stream = RestApiStream(url=\"http://localhost:5000/api/v1/data\", method=\"POST\", content_type=\"json\") headers={\"Authorization\": \"Bearer ...\"})","title":"RestApiStream Objects"},{"location":"output-streams/restapistream/#write","text":"def write(data: Any) -> Response [view_source] Processes the data and writes it to the output stream. Arguments data ( Any ): The data to be written to the output stream. Returns Response : The response from the REST API. Examples >>> from darcyai.output.rest_api_stream import RestApiStream >>> rest_api_stream = RestApiStream(url=\"http://localhost:5000/api/v1/data\", method=\"POST\", content_type=\"json\") headers={\"Authorization\": \"Bearer ...\"}) >>> response = rest_api_stream.write({\"data\": \"some data\"})","title":"write"},{"location":"output-streams/restapistream/#close","text":"def close() -> None [view_source] Closes the output stream.","title":"close"}]}